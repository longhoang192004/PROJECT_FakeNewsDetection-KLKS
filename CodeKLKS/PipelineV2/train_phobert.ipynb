{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9024b4bd227642559c089b6ba0227743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_694ef61586c1497889ff762f59897776",
              "IPY_MODEL_591411da12ea4e8db58d06c07b0820fa",
              "IPY_MODEL_f983f68c156d4debb3536c4da4d0181c"
            ],
            "layout": "IPY_MODEL_ba07908e4fca4e8a8a53f52a33536e74"
          }
        },
        "694ef61586c1497889ff762f59897776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778a7adc3f2a44558c1c343170d7a1d9",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9b909b4aab498c808765a7b08cb3d4",
            "value": "Loading weights: 100%"
          }
        },
        "591411da12ea4e8db58d06c07b0820fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b461ebc5c314805ab20989b8047bc5a",
            "max": 197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095670fc94bc40d5a592aad1fa32143f",
            "value": 197
          }
        },
        "f983f68c156d4debb3536c4da4d0181c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b5dae7efc34acd8c9c251838973107",
            "placeholder": "​",
            "style": "IPY_MODEL_13c9f2441850422fbc5da6b3cc253f0c",
            "value": " 197/197 [00:00&lt;00:00, 484.17it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]"
          }
        },
        "ba07908e4fca4e8a8a53f52a33536e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "778a7adc3f2a44558c1c343170d7a1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9b909b4aab498c808765a7b08cb3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b461ebc5c314805ab20989b8047bc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095670fc94bc40d5a592aad1fa32143f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41b5dae7efc34acd8c9c251838973107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c9f2441850422fbc5da6b3cc253f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgA3bi-rcTEE",
        "outputId": "489823f8-efc2-4d9c-c44d-6ab87e0c1f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/PROJECT_FakeNewsDetection-KLKS/CodeKLKS/PipelineV2\" /content/PipelineV2\n",
        "!cp \"/content/drive/MyDrive/PROJECT_FakeNewsDetection-KLKS/fakenewsdatasetv1.csv\" /content/\n",
        "\n",
        "!pip install -q emoji transformers\n"
      ],
      "metadata": {
        "id": "gTSqdTPecqjZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!python -m PipelineV2.run_pipeline --data_path /content/fakenewsdatasetv1.csv --output_dir /content/outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLFFN0OiduXn",
        "outputId": "1e64bfbb-933c-46a4-e67c-0e067366481d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\n",
            "[*] Data path:   /content/fakenewsdatasetv1.csv\n",
            "[*] Output dir:  /content/outputs\n",
            "[*] Seed:        42\n",
            "[*] Min words:   8\n",
            "[*] Near-dup thr:0.92\n",
            "\n",
            "================================================================================\n",
            "PIPELINE V2 - LOAD DATA\n",
            "================================================================================\n",
            "  Loaded: 1843 samples\n",
            "\n",
            "  Cleaning text (unified pipeline)...\n",
            "  After filter (>=8 words, >=10 chars): 1843 (removed 0)\n",
            "  After exact dedup: 1843 (removed 0)\n",
            "\n",
            "  Dataset: 1843 samples | REAL=974 (52.8%) | FAKE=869 (47.2%)\n",
            "\n",
            "================================================================================\n",
            "BUILDING NEAR-DUP CLUSTERS\n",
            "================================================================================\n",
            "  Groups: 1810 | Largest group size: 8\n",
            "  Top 5 group sizes:\n",
            "group\n",
            "35     8\n",
            "136    7\n",
            "26     4\n",
            "67     2\n",
            "163    2\n",
            "\n",
            "================================================================================\n",
            "LEAK-SAFE SPLIT (STRATIFIED + GROUP-AWARE)\n",
            "================================================================================\n",
            "  Picked fold 1 for TEST: size=184 (0.100)\n",
            "  Picked fold 5 for VAL: size=182 (0.110)\n",
            "  Train:  1477 | REAL=777 (52.6%) | FAKE=700 (47.4%) | groups=1449\n",
            "  Val  :   182 | REAL=98 (53.8%) | FAKE=84 (46.2%) | groups=182\n",
            "  Test :   184 | REAL=99 (53.8%) | FAKE=85 (46.2%) | groups=179\n",
            "\n",
            "  Group overlap: Train&Val=0 | Train&Test=0 | Val&Test=0\n",
            "\n",
            "================================================================================\n",
            "LEAK REPORT\n",
            "================================================================================\n",
            "\n",
            "  -- Exact Leak Check --\n",
            "  Exact leak Train&Val: 0\n",
            "  Exact leak Train&Test: 0\n",
            "  Exact leak Val&Test: 0\n",
            "\n",
            "  -- Near-dup Leak Check --\n",
            "  Val->Train:  {'mean': 0.34677088260650635, 'median': 0.3132728040218353, 'p95': 0.6124265789985657, 'max': 0.8284850120544434, 'count_ge_thr': 0}\n",
            "  Test->Train: {'mean': 0.3800369203090668, 'median': 0.3513627350330353, 'p95': 0.7006479501724243, 'max': 0.9293544292449951, 'count_ge_thr': 1}\n",
            "  Test->Val:   {'mean': 0.2964983880519867, 'median': 0.272350549697876, 'p95': 0.4443407654762268, 'max': 0.7990162372589111, 'count_ge_thr': 0}\n",
            "\n",
            "================================================================================\n",
            "SAVING OUTPUTS\n",
            "================================================================================\n",
            "  Saved to: /content/outputs\n",
            "    - train.csv      (1477 samples)\n",
            "    - val.csv        (182 samples)\n",
            "    - test.csv       (184 samples)\n",
            "    - dataset_clean_dedup.csv\n",
            "    - leak_report.json\n",
            "    - stats.json\n",
            "\n",
            "================================================================================\n",
            "PIPELINE V2 COMPLETE [OK]\n",
            "================================================================================\n",
            "\n",
            "[OK] Total processed: 1843 samples\n",
            "   train:  1477 (80.1%)\n",
            "   val  :   182 (9.9%)\n",
            "   test :   184 (10.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m PipelineV2.train_phobert \\\n",
        "    --data_path /content/fakenewsdatasetv1.csv \\\n",
        "    --output_dir /content/outputs \\\n",
        "    --epochs 5 \\\n",
        "    --batch_size 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXlmPX_3d1bp",
        "outputId": "dfceaeb6-5d3f-454d-8b61-738922a064aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PHOBERT FINE-TUNING FOR FAKE NEWS DETECTION\n",
            "================================================================================\n",
            "  Device: cuda\n",
            "  Model:  vinai/phobert-base\n",
            "  Epochs: 5\n",
            "  Batch:  8\n",
            "  LR:     2e-05\n",
            "\n",
            "================================================================================\n",
            "PIPELINE V2 - LOAD DATA\n",
            "================================================================================\n",
            "  Loaded: 1843 samples\n",
            "\n",
            "  Cleaning text (unified pipeline)...\n",
            "  After filter (>=8 words, >=10 chars): 1843 (removed 0)\n",
            "  After exact dedup: 1843 (removed 0)\n",
            "\n",
            "  Dataset: 1843 samples | REAL=974 (52.8%) | FAKE=869 (47.2%)\n",
            "\n",
            "================================================================================\n",
            "BUILDING NEAR-DUP CLUSTERS\n",
            "================================================================================\n",
            "  Groups: 1810 | Largest group size: 8\n",
            "  Top 5 group sizes:\n",
            "group\n",
            "35     8\n",
            "136    7\n",
            "26     4\n",
            "67     2\n",
            "163    2\n",
            "\n",
            "================================================================================\n",
            "LEAK-SAFE SPLIT (STRATIFIED + GROUP-AWARE)\n",
            "================================================================================\n",
            "  Picked fold 1 for TEST: size=184 (0.100)\n",
            "  Picked fold 5 for VAL: size=182 (0.110)\n",
            "  Train:  1477 | REAL=777 (52.6%) | FAKE=700 (47.4%) | groups=1449\n",
            "  Val  :   182 | REAL=98 (53.8%) | FAKE=84 (46.2%) | groups=182\n",
            "  Test :   184 | REAL=99 (53.8%) | FAKE=85 (46.2%) | groups=179\n",
            "\n",
            "  Group overlap: Train&Val=0 | Train&Test=0 | Val&Test=0\n",
            "\n",
            "================================================================================\n",
            "LEAK REPORT\n",
            "================================================================================\n",
            "\n",
            "  -- Exact Leak Check --\n",
            "  Exact leak Train&Val: 0\n",
            "  Exact leak Train&Test: 0\n",
            "  Exact leak Val&Test: 0\n",
            "\n",
            "  -- Near-dup Leak Check --\n",
            "  Val->Train:  {'mean': 0.34677088260650635, 'median': 0.3132728040218353, 'p95': 0.6124265789985657, 'max': 0.8284850120544434, 'count_ge_thr': 0}\n",
            "  Test->Train: {'mean': 0.3800369203090668, 'median': 0.3513627350330353, 'p95': 0.7006479501724243, 'max': 0.9293544292449951, 'count_ge_thr': 1}\n",
            "  Test->Val:   {'mean': 0.2964983880519867, 'median': 0.272350549697876, 'p95': 0.4443407654762268, 'max': 0.7990162372589111, 'count_ge_thr': 0}\n",
            "\n",
            "================================================================================\n",
            "SAVING OUTPUTS\n",
            "================================================================================\n",
            "  Saved to: /content/outputs\n",
            "    - train.csv      (1477 samples)\n",
            "    - val.csv        (182 samples)\n",
            "    - test.csv       (184 samples)\n",
            "    - dataset_clean_dedup.csv\n",
            "    - leak_report.json\n",
            "    - stats.json\n",
            "\n",
            "================================================================================\n",
            "PIPELINE V2 COMPLETE [OK]\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LOADING TOKENIZER\n",
            "================================================================================\n",
            "config.json: 100% 557/557 [00:00<00:00, 2.77MB/s]\n",
            "vocab.txt: 895kB [00:00, 38.4MB/s]\n",
            "bpe.codes: 1.14MB [00:00, 118MB/s]\n",
            "tokenizer.json: 3.13MB [00:00, 159MB/s]\n",
            "  Tokenizer: vinai/phobert-base (vocab=64001)\n",
            "\n",
            "================================================================================\n",
            "CREATING DATALOADERS (DYNAMIC PADDING + AUGMENTATION)\n",
            "================================================================================\n",
            "  Train: 1477 samples, 185 batches\n",
            "  Val:   182 samples, 23 batches\n",
            "  Test:  184 samples, 23 batches\n",
            "  Augmentation: prob=0.3\n",
            "\n",
            "================================================================================\n",
            "LOADING MODEL\n",
            "================================================================================\n",
            "pytorch_model.bin: 100% 543M/543M [00:05<00:00, 92.6MB/s]\n",
            "Loading weights: 100% 197/197 [00:00<00:00, 1238.09it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]\n",
            "model.safetensors:   0% 0.00/543M [00:00<?, ?B/s]\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: vinai/phobert-base\n",
            "Key                             | Status     | \n",
            "--------------------------------+------------+-\n",
            "roberta.embeddings.position_ids | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "roberta.pooler.dense.bias       | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.dense.weight            | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.dense.bias              | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "roberta.pooler.dense.weight     | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.decoder.bias            | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.layer_norm.weight       | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.layer_norm.bias         | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.decoder.weight          | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "lm_head.bias                    | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "classifier.dense.weight         | \u001b[31mMISSING\u001b[0m    | \n",
            "classifier.out_proj.bias        | \u001b[31mMISSING\u001b[0m    | \n",
            "classifier.dense.bias           | \u001b[31mMISSING\u001b[0m    | \n",
            "classifier.out_proj.weight      | \u001b[31mMISSING\u001b[0m    | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- \u001b[31mMISSING\u001b[0m\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n",
            "  Total params:     134,999,810\n",
            "  Trainable params: 134,999,810 (100.0%)\n",
            "  Class counts [REAL, FAKE]: [777 700]\n",
            "  Class weights: [0.9504505 1.055    ]\n",
            "  Total steps:  925\n",
            "  Warmup steps: 92\n",
            "\n",
            "================================================================================\n",
            "TRAINING\n",
            "================================================================================\n",
            "\n",
            "model.safetensors:  26% 140M/543M [00:02<00:04, 87.3MB/s] \n",
            "Epoch 1/5:   0% 0/185 [00:02<?, ?it/s, loss=0.6799]\u001b[A\n",
            "model.safetensors:  38% 207M/543M [00:02<00:03, 103MB/s] \n",
            "Epoch 1/5:   1% 1/185 [00:02<06:35,  2.15s/it, loss=0.6711]\u001b[A\n",
            "model.safetensors:  63% 342M/543M [00:03<00:01, 164MB/s]\n",
            "Epoch 1/5:   1% 2/185 [00:02<03:20,  1.10s/it, loss=0.6821]\u001b[A\n",
            "model.safetensors:  88% 476M/543M [00:03<00:00, 255MB/s]\n",
            "Epoch 1/5:   2% 3/185 [00:03<02:20,  1.29it/s, loss=0.6919]\u001b[A\n",
            "model.safetensors: 100% 543M/543M [00:03<00:00, 146MB/s]\n",
            "\n",
            "Epoch 1/5:   2% 4/185 [00:03<01:51,  1.62it/s, loss=0.6394]\u001b[A\n",
            "Epoch 1/5:   3% 5/185 [00:03<01:34,  1.91it/s, loss=0.6394]\u001b[A\n",
            "Epoch 1/5:   3% 5/185 [00:03<01:34,  1.91it/s, loss=0.6978]\u001b[A\n",
            "Epoch 1/5:   3% 6/185 [00:03<01:23,  2.15it/s, loss=0.6978]\u001b[A\n",
            "Epoch 1/5:   3% 6/185 [00:04<01:23,  2.15it/s, loss=0.6903]\u001b[A\n",
            "Epoch 1/5:   4% 7/185 [00:04<01:17,  2.31it/s, loss=0.6903]\u001b[A\n",
            "Epoch 1/5:   4% 7/185 [00:04<01:17,  2.31it/s, loss=0.6986]\u001b[A\n",
            "Epoch 1/5:   4% 8/185 [00:04<01:11,  2.47it/s, loss=0.6986]\u001b[A\n",
            "Epoch 1/5:   4% 8/185 [00:05<01:11,  2.47it/s, loss=0.7574]\u001b[A\n",
            "Epoch 1/5:   5% 9/185 [00:05<01:08,  2.58it/s, loss=0.7574]\u001b[A\n",
            "Epoch 1/5:   5% 9/185 [00:05<01:08,  2.58it/s, loss=0.6503]\u001b[A\n",
            "Epoch 1/5:   5% 10/185 [00:05<01:06,  2.65it/s, loss=0.6503]\u001b[A\n",
            "Epoch 1/5:   5% 10/185 [00:05<01:06,  2.65it/s, loss=0.6869]\u001b[A\n",
            "Epoch 1/5:   6% 11/185 [00:05<00:55,  3.12it/s, loss=0.6869]\u001b[A\n",
            "Epoch 1/5:   6% 11/185 [00:05<00:55,  3.12it/s, loss=0.6499]\u001b[A\n",
            "Epoch 1/5:   6% 12/185 [00:05<00:57,  2.99it/s, loss=0.6499]\u001b[A\n",
            "Epoch 1/5:   6% 12/185 [00:06<00:57,  2.99it/s, loss=0.6791]\u001b[A\n",
            "Epoch 1/5:   7% 13/185 [00:06<00:53,  3.22it/s, loss=0.6791]\u001b[A\n",
            "Epoch 1/5:   7% 13/185 [00:06<00:53,  3.22it/s, loss=0.6692]\u001b[A\n",
            "Epoch 1/5:   8% 14/185 [00:06<00:55,  3.11it/s, loss=0.6692]\u001b[A\n",
            "Epoch 1/5:   8% 14/185 [00:06<00:55,  3.11it/s, loss=0.7098]\u001b[A\n",
            "Epoch 1/5:   8% 15/185 [00:06<00:56,  3.02it/s, loss=0.7098]\u001b[A\n",
            "Epoch 1/5:   8% 15/185 [00:07<00:56,  3.02it/s, loss=0.6262]\u001b[A\n",
            "Epoch 1/5:   9% 16/185 [00:07<00:57,  2.96it/s, loss=0.6262]\u001b[A\n",
            "Epoch 1/5:   9% 16/185 [00:07<00:57,  2.96it/s, loss=0.6469]\u001b[A\n",
            "Epoch 1/5:   9% 17/185 [00:07<00:57,  2.94it/s, loss=0.6469]\u001b[A\n",
            "Epoch 1/5:   9% 17/185 [00:07<00:57,  2.94it/s, loss=0.7111]\u001b[A\n",
            "Epoch 1/5:  10% 18/185 [00:07<00:57,  2.89it/s, loss=0.7111]\u001b[A\n",
            "Epoch 1/5:  10% 18/185 [00:08<00:57,  2.89it/s, loss=0.6601]\u001b[A\n",
            "Epoch 1/5:  10% 19/185 [00:08<00:57,  2.88it/s, loss=0.6601]\u001b[A\n",
            "Epoch 1/5:  10% 19/185 [00:08<00:57,  2.88it/s, loss=0.5978]\u001b[A\n",
            "Epoch 1/5:  11% 20/185 [00:08<00:58,  2.83it/s, loss=0.5978]\u001b[A\n",
            "Epoch 1/5:  11% 20/185 [00:09<00:58,  2.83it/s, loss=0.6333]\u001b[A\n",
            "Epoch 1/5:  11% 21/185 [00:09<00:57,  2.84it/s, loss=0.6333]\u001b[A\n",
            "Epoch 1/5:  11% 21/185 [00:09<00:57,  2.84it/s, loss=0.7407]\u001b[A\n",
            "Epoch 1/5:  12% 22/185 [00:09<00:57,  2.85it/s, loss=0.7407]\u001b[A\n",
            "Epoch 1/5:  12% 22/185 [00:09<00:57,  2.85it/s, loss=0.7086]\u001b[A\n",
            "Epoch 1/5:  12% 23/185 [00:09<00:56,  2.86it/s, loss=0.7086]\u001b[A\n",
            "Epoch 1/5:  12% 23/185 [00:10<00:56,  2.86it/s, loss=0.7074]\u001b[A\n",
            "Epoch 1/5:  13% 24/185 [00:10<00:56,  2.85it/s, loss=0.7074]\u001b[A\n",
            "Epoch 1/5:  13% 24/185 [00:10<00:56,  2.85it/s, loss=0.7093]\u001b[A\n",
            "Epoch 1/5:  14% 25/185 [00:10<00:46,  3.43it/s, loss=0.7093]\u001b[A\n",
            "Epoch 1/5:  14% 25/185 [00:10<00:46,  3.43it/s, loss=0.6582]\u001b[A\n",
            "Epoch 1/5:  14% 26/185 [00:10<00:47,  3.36it/s, loss=0.6582]\u001b[A\n",
            "Epoch 1/5:  14% 26/185 [00:10<00:47,  3.36it/s, loss=0.6587]\u001b[A\n",
            "Epoch 1/5:  15% 27/185 [00:10<00:49,  3.16it/s, loss=0.6587]\u001b[A\n",
            "Epoch 1/5:  15% 27/185 [00:11<00:49,  3.16it/s, loss=0.7099]\u001b[A\n",
            "Epoch 1/5:  15% 28/185 [00:11<00:51,  3.04it/s, loss=0.7099]\u001b[A\n",
            "Epoch 1/5:  15% 28/185 [00:11<00:51,  3.04it/s, loss=0.6413]\u001b[A\n",
            "Epoch 1/5:  16% 29/185 [00:11<00:52,  2.98it/s, loss=0.6413]\u001b[A\n",
            "Epoch 1/5:  16% 29/185 [00:11<00:52,  2.98it/s, loss=0.7333]\u001b[A\n",
            "Epoch 1/5:  16% 30/185 [00:11<00:53,  2.90it/s, loss=0.7333]\u001b[A\n",
            "Epoch 1/5:  16% 30/185 [00:12<00:53,  2.90it/s, loss=0.6469]\u001b[A\n",
            "Epoch 1/5:  17% 31/185 [00:12<00:53,  2.88it/s, loss=0.6469]\u001b[A\n",
            "Epoch 1/5:  17% 31/185 [00:12<00:53,  2.88it/s, loss=0.6123]\u001b[A\n",
            "Epoch 1/5:  17% 32/185 [00:12<00:53,  2.84it/s, loss=0.6123]\u001b[A\n",
            "Epoch 1/5:  17% 32/185 [00:13<00:53,  2.84it/s, loss=0.6199]\u001b[A\n",
            "Epoch 1/5:  18% 33/185 [00:13<00:54,  2.80it/s, loss=0.6199]\u001b[A\n",
            "Epoch 1/5:  18% 33/185 [00:13<00:54,  2.80it/s, loss=0.6645]\u001b[A\n",
            "Epoch 1/5:  18% 34/185 [00:13<00:53,  2.80it/s, loss=0.6645]\u001b[A\n",
            "Epoch 1/5:  18% 34/185 [00:13<00:53,  2.80it/s, loss=0.6595]\u001b[A\n",
            "Epoch 1/5:  19% 35/185 [00:13<00:53,  2.81it/s, loss=0.6595]\u001b[A\n",
            "Epoch 1/5:  19% 35/185 [00:14<00:53,  2.81it/s, loss=0.6267]\u001b[A\n",
            "Epoch 1/5:  19% 36/185 [00:14<00:53,  2.80it/s, loss=0.6267]\u001b[A\n",
            "Epoch 1/5:  19% 36/185 [00:14<00:53,  2.80it/s, loss=0.6235]\u001b[A\n",
            "Epoch 1/5:  20% 37/185 [00:14<00:53,  2.76it/s, loss=0.6235]\u001b[A\n",
            "Epoch 1/5:  20% 37/185 [00:14<00:53,  2.76it/s, loss=0.5618]\u001b[A\n",
            "Epoch 1/5:  21% 38/185 [00:14<00:53,  2.77it/s, loss=0.5618]\u001b[A\n",
            "Epoch 1/5:  21% 38/185 [00:15<00:53,  2.77it/s, loss=0.6433]\u001b[A\n",
            "Epoch 1/5:  21% 39/185 [00:15<00:52,  2.78it/s, loss=0.6433]\u001b[A\n",
            "Epoch 1/5:  21% 39/185 [00:15<00:52,  2.78it/s, loss=0.6310]\u001b[A\n",
            "Epoch 1/5:  22% 40/185 [00:15<00:52,  2.78it/s, loss=0.6310]\u001b[A\n",
            "Epoch 1/5:  22% 40/185 [00:15<00:52,  2.78it/s, loss=0.6367]\u001b[A\n",
            "Epoch 1/5:  22% 41/185 [00:15<00:46,  3.12it/s, loss=0.6367]\u001b[A\n",
            "Epoch 1/5:  22% 41/185 [00:16<00:46,  3.12it/s, loss=0.7196]\u001b[A\n",
            "Epoch 1/5:  23% 42/185 [00:16<00:46,  3.05it/s, loss=0.7196]\u001b[A\n",
            "Epoch 1/5:  23% 42/185 [00:16<00:46,  3.05it/s, loss=0.6056]\u001b[A\n",
            "Epoch 1/5:  23% 43/185 [00:16<00:47,  2.98it/s, loss=0.6056]\u001b[A\n",
            "Epoch 1/5:  23% 43/185 [00:16<00:47,  2.98it/s, loss=0.5932]\u001b[A\n",
            "Epoch 1/5:  24% 44/185 [00:16<00:48,  2.89it/s, loss=0.5932]\u001b[A\n",
            "Epoch 1/5:  24% 44/185 [00:17<00:48,  2.89it/s, loss=0.5841]\u001b[A\n",
            "Epoch 1/5:  24% 45/185 [00:17<00:48,  2.87it/s, loss=0.5841]\u001b[A\n",
            "Epoch 1/5:  24% 45/185 [00:17<00:48,  2.87it/s, loss=0.5454]\u001b[A\n",
            "Epoch 1/5:  25% 46/185 [00:17<00:49,  2.83it/s, loss=0.5454]\u001b[A\n",
            "Epoch 1/5:  25% 46/185 [00:17<00:49,  2.83it/s, loss=0.5639]\u001b[A\n",
            "Epoch 1/5:  25% 47/185 [00:17<00:43,  3.14it/s, loss=0.5639]\u001b[A\n",
            "Epoch 1/5:  25% 47/185 [00:18<00:43,  3.14it/s, loss=0.5665]\u001b[A\n",
            "Epoch 1/5:  26% 48/185 [00:18<00:45,  3.03it/s, loss=0.5665]\u001b[A\n",
            "Epoch 1/5:  26% 48/185 [00:18<00:45,  3.03it/s, loss=0.4576]\u001b[A\n",
            "Epoch 1/5:  26% 49/185 [00:18<00:46,  2.94it/s, loss=0.4576]\u001b[A\n",
            "Epoch 1/5:  26% 49/185 [00:18<00:46,  2.94it/s, loss=0.7011]\u001b[A\n",
            "Epoch 1/5:  27% 50/185 [00:18<00:46,  2.91it/s, loss=0.7011]\u001b[A\n",
            "Epoch 1/5:  27% 50/185 [00:19<00:46,  2.91it/s, loss=0.5383]\u001b[A\n",
            "Epoch 1/5:  28% 51/185 [00:19<00:39,  3.40it/s, loss=0.5383]\u001b[A\n",
            "Epoch 1/5:  28% 51/185 [00:19<00:39,  3.40it/s, loss=0.5373]\u001b[A\n",
            "Epoch 1/5:  28% 52/185 [00:19<00:41,  3.23it/s, loss=0.5373]\u001b[A\n",
            "Epoch 1/5:  28% 52/185 [00:19<00:41,  3.23it/s, loss=0.5141]\u001b[A\n",
            "Epoch 1/5:  29% 53/185 [00:19<00:35,  3.75it/s, loss=0.5141]\u001b[A\n",
            "Epoch 1/5:  29% 53/185 [00:19<00:35,  3.75it/s, loss=0.5263]\u001b[A\n",
            "Epoch 1/5:  29% 54/185 [00:19<00:38,  3.39it/s, loss=0.5263]\u001b[A\n",
            "Epoch 1/5:  29% 54/185 [00:20<00:38,  3.39it/s, loss=0.5506]\u001b[A\n",
            "Epoch 1/5:  30% 55/185 [00:20<00:41,  3.16it/s, loss=0.5506]\u001b[A\n",
            "Epoch 1/5:  30% 55/185 [00:20<00:41,  3.16it/s, loss=0.4856]\u001b[A\n",
            "Epoch 1/5:  30% 56/185 [00:20<00:43,  3.00it/s, loss=0.4856]\u001b[A\n",
            "Epoch 1/5:  30% 56/185 [00:21<00:43,  3.00it/s, loss=0.7172]\u001b[A\n",
            "Epoch 1/5:  31% 57/185 [00:21<00:43,  2.91it/s, loss=0.7172]\u001b[A\n",
            "Epoch 1/5:  31% 57/185 [00:21<00:43,  2.91it/s, loss=0.4113]\u001b[A\n",
            "Epoch 1/5:  31% 58/185 [00:21<00:44,  2.87it/s, loss=0.4113]\u001b[A\n",
            "Epoch 1/5:  31% 58/185 [00:21<00:44,  2.87it/s, loss=0.4481]\u001b[A\n",
            "Epoch 1/5:  32% 59/185 [00:21<00:43,  2.87it/s, loss=0.4481]\u001b[A\n",
            "Epoch 1/5:  32% 59/185 [00:22<00:43,  2.87it/s, loss=0.4160]\u001b[A\n",
            "Epoch 1/5:  32% 60/185 [00:22<00:44,  2.82it/s, loss=0.4160]\u001b[A\n",
            "Epoch 1/5:  32% 60/185 [00:22<00:44,  2.82it/s, loss=0.4700]\u001b[A\n",
            "Epoch 1/5:  33% 61/185 [00:22<00:45,  2.75it/s, loss=0.4700]\u001b[A\n",
            "Epoch 1/5:  33% 61/185 [00:22<00:45,  2.75it/s, loss=0.4828]\u001b[A\n",
            "Epoch 1/5:  34% 62/185 [00:22<00:44,  2.78it/s, loss=0.4828]\u001b[A\n",
            "Epoch 1/5:  34% 62/185 [00:23<00:44,  2.78it/s, loss=0.4476]\u001b[A\n",
            "Epoch 1/5:  34% 63/185 [00:23<00:44,  2.77it/s, loss=0.4476]\u001b[A\n",
            "Epoch 1/5:  34% 63/185 [00:23<00:44,  2.77it/s, loss=0.4510]\u001b[A\n",
            "Epoch 1/5:  35% 64/185 [00:23<00:42,  2.82it/s, loss=0.4510]\u001b[A\n",
            "Epoch 1/5:  35% 64/185 [00:23<00:42,  2.82it/s, loss=0.4470]\u001b[A\n",
            "Epoch 1/5:  35% 65/185 [00:23<00:36,  3.28it/s, loss=0.4470]\u001b[A\n",
            "Epoch 1/5:  35% 65/185 [00:24<00:36,  3.28it/s, loss=0.3854]\u001b[A\n",
            "Epoch 1/5:  36% 66/185 [00:24<00:38,  3.09it/s, loss=0.3854]\u001b[A\n",
            "Epoch 1/5:  36% 66/185 [00:24<00:38,  3.09it/s, loss=0.4305]\u001b[A\n",
            "Epoch 1/5:  36% 67/185 [00:24<00:39,  3.00it/s, loss=0.4305]\u001b[A\n",
            "Epoch 1/5:  36% 67/185 [00:24<00:39,  3.00it/s, loss=0.4070]\u001b[A\n",
            "Epoch 1/5:  37% 68/185 [00:24<00:40,  2.92it/s, loss=0.4070]\u001b[A\n",
            "Epoch 1/5:  37% 68/185 [00:25<00:40,  2.92it/s, loss=0.3837]\u001b[A\n",
            "Epoch 1/5:  37% 69/185 [00:25<00:40,  2.86it/s, loss=0.3837]\u001b[A\n",
            "Epoch 1/5:  37% 69/185 [00:25<00:40,  2.86it/s, loss=0.4194]\u001b[A\n",
            "Epoch 1/5:  38% 70/185 [00:25<00:40,  2.85it/s, loss=0.4194]\u001b[A\n",
            "Epoch 1/5:  38% 70/185 [00:25<00:40,  2.85it/s, loss=0.4068]\u001b[A\n",
            "Epoch 1/5:  38% 71/185 [00:25<00:40,  2.84it/s, loss=0.4068]\u001b[A\n",
            "Epoch 1/5:  38% 71/185 [00:26<00:40,  2.84it/s, loss=0.3231]\u001b[A\n",
            "Epoch 1/5:  39% 72/185 [00:26<00:41,  2.72it/s, loss=0.3231]\u001b[A\n",
            "Epoch 1/5:  39% 72/185 [00:26<00:41,  2.72it/s, loss=0.3848]\u001b[A\n",
            "Epoch 1/5:  39% 73/185 [00:26<00:41,  2.71it/s, loss=0.3848]\u001b[A\n",
            "Epoch 1/5:  39% 73/185 [00:27<00:41,  2.71it/s, loss=0.2800]\u001b[A\n",
            "Epoch 1/5:  40% 74/185 [00:27<00:40,  2.72it/s, loss=0.2800]\u001b[A\n",
            "Epoch 1/5:  40% 74/185 [00:27<00:40,  2.72it/s, loss=0.4299]\u001b[A\n",
            "Epoch 1/5:  41% 75/185 [00:27<00:37,  2.94it/s, loss=0.4299]\u001b[A\n",
            "Epoch 1/5:  41% 75/185 [00:27<00:37,  2.94it/s, loss=0.3108]\u001b[A\n",
            "Epoch 1/5:  41% 76/185 [00:27<00:37,  2.87it/s, loss=0.3108]\u001b[A\n",
            "Epoch 1/5:  41% 76/185 [00:28<00:37,  2.87it/s, loss=0.6038]\u001b[A\n",
            "Epoch 1/5:  42% 77/185 [00:28<00:38,  2.80it/s, loss=0.6038]\u001b[A\n",
            "Epoch 1/5:  42% 77/185 [00:28<00:38,  2.80it/s, loss=0.3772]\u001b[A\n",
            "Epoch 1/5:  42% 78/185 [00:28<00:31,  3.41it/s, loss=0.3772]\u001b[A\n",
            "Epoch 1/5:  42% 78/185 [00:28<00:31,  3.41it/s, loss=0.4381]\u001b[A\n",
            "Epoch 1/5:  43% 79/185 [00:28<00:30,  3.46it/s, loss=0.4381]\u001b[A\n",
            "Epoch 1/5:  43% 79/185 [00:28<00:30,  3.46it/s, loss=0.4541]\u001b[A\n",
            "Epoch 1/5:  43% 80/185 [00:28<00:32,  3.20it/s, loss=0.4541]\u001b[A\n",
            "Epoch 1/5:  43% 80/185 [00:29<00:32,  3.20it/s, loss=0.2276]\u001b[A\n",
            "Epoch 1/5:  44% 81/185 [00:29<00:34,  3.02it/s, loss=0.2276]\u001b[A\n",
            "Epoch 1/5:  44% 81/185 [00:29<00:34,  3.02it/s, loss=0.2573]\u001b[A\n",
            "Epoch 1/5:  44% 82/185 [00:29<00:34,  3.03it/s, loss=0.2573]\u001b[A\n",
            "Epoch 1/5:  44% 82/185 [00:29<00:34,  3.03it/s, loss=0.2679]\u001b[A\n",
            "Epoch 1/5:  45% 83/185 [00:29<00:34,  2.93it/s, loss=0.2679]\u001b[A\n",
            "Epoch 1/5:  45% 83/185 [00:30<00:34,  2.93it/s, loss=0.1913]\u001b[A\n",
            "Epoch 1/5:  45% 84/185 [00:30<00:35,  2.88it/s, loss=0.1913]\u001b[A\n",
            "Epoch 1/5:  45% 84/185 [00:30<00:35,  2.88it/s, loss=0.4914]\u001b[A\n",
            "Epoch 1/5:  46% 85/185 [00:30<00:34,  2.86it/s, loss=0.4914]\u001b[A\n",
            "Epoch 1/5:  46% 85/185 [00:31<00:34,  2.86it/s, loss=0.1258]\u001b[A\n",
            "Epoch 1/5:  46% 86/185 [00:31<00:34,  2.84it/s, loss=0.1258]\u001b[A\n",
            "Epoch 1/5:  46% 86/185 [00:31<00:34,  2.84it/s, loss=0.4436]\u001b[A\n",
            "Epoch 1/5:  47% 87/185 [00:31<00:34,  2.82it/s, loss=0.4436]\u001b[A\n",
            "Epoch 1/5:  47% 87/185 [00:31<00:34,  2.82it/s, loss=0.1078]\u001b[A\n",
            "Epoch 1/5:  48% 88/185 [00:31<00:34,  2.81it/s, loss=0.1078]\u001b[A\n",
            "Epoch 1/5:  48% 88/185 [00:32<00:34,  2.81it/s, loss=0.1870]\u001b[A\n",
            "Epoch 1/5:  48% 89/185 [00:32<00:32,  2.91it/s, loss=0.1870]\u001b[A\n",
            "Epoch 1/5:  48% 89/185 [00:32<00:32,  2.91it/s, loss=0.2627]\u001b[A\n",
            "Epoch 1/5:  49% 90/185 [00:32<00:33,  2.84it/s, loss=0.2627]\u001b[A\n",
            "Epoch 1/5:  49% 90/185 [00:32<00:33,  2.84it/s, loss=0.2179]\u001b[A\n",
            "Epoch 1/5:  49% 91/185 [00:32<00:33,  2.81it/s, loss=0.2179]\u001b[A\n",
            "Epoch 1/5:  49% 91/185 [00:33<00:33,  2.81it/s, loss=0.1482]\u001b[A\n",
            "Epoch 1/5:  50% 92/185 [00:33<00:33,  2.78it/s, loss=0.1482]\u001b[A\n",
            "Epoch 1/5:  50% 92/185 [00:33<00:33,  2.78it/s, loss=0.1262]\u001b[A\n",
            "Epoch 1/5:  50% 93/185 [00:33<00:33,  2.78it/s, loss=0.1262]\u001b[A\n",
            "Epoch 1/5:  50% 93/185 [00:33<00:33,  2.78it/s, loss=0.2178]\u001b[A\n",
            "Epoch 1/5:  51% 94/185 [00:33<00:32,  2.76it/s, loss=0.2178]\u001b[A\n",
            "Epoch 1/5:  51% 94/185 [00:34<00:32,  2.76it/s, loss=0.1648]\u001b[A\n",
            "Epoch 1/5:  51% 95/185 [00:34<00:32,  2.76it/s, loss=0.1648]\u001b[A\n",
            "Epoch 1/5:  51% 95/185 [00:34<00:32,  2.76it/s, loss=0.0898]\u001b[A\n",
            "Epoch 1/5:  52% 96/185 [00:34<00:32,  2.76it/s, loss=0.0898]\u001b[A\n",
            "Epoch 1/5:  52% 96/185 [00:34<00:32,  2.76it/s, loss=0.4390]\u001b[A\n",
            "Epoch 1/5:  52% 97/185 [00:34<00:31,  2.77it/s, loss=0.4390]\u001b[A\n",
            "Epoch 1/5:  52% 97/185 [00:35<00:31,  2.77it/s, loss=0.0700]\u001b[A\n",
            "Epoch 1/5:  53% 98/185 [00:35<00:31,  2.77it/s, loss=0.0700]\u001b[A\n",
            "Epoch 1/5:  53% 98/185 [00:35<00:31,  2.77it/s, loss=0.0630]\u001b[A\n",
            "Epoch 1/5:  54% 99/185 [00:35<00:25,  3.34it/s, loss=0.0630]\u001b[A\n",
            "Epoch 1/5:  54% 99/185 [00:35<00:25,  3.34it/s, loss=0.1329]\u001b[A\n",
            "Epoch 1/5:  54% 100/185 [00:35<00:27,  3.14it/s, loss=0.1329]\u001b[A\n",
            "Epoch 1/5:  54% 100/185 [00:36<00:27,  3.14it/s, loss=0.0772]\u001b[A\n",
            "Epoch 1/5:  55% 101/185 [00:36<00:27,  3.03it/s, loss=0.0772]\u001b[A\n",
            "Epoch 1/5:  55% 101/185 [00:36<00:27,  3.03it/s, loss=0.4543]\u001b[A\n",
            "Epoch 1/5:  55% 102/185 [00:36<00:28,  2.94it/s, loss=0.4543]\u001b[A\n",
            "Epoch 1/5:  55% 102/185 [00:36<00:28,  2.94it/s, loss=0.0457]\u001b[A\n",
            "Epoch 1/5:  56% 103/185 [00:36<00:28,  2.88it/s, loss=0.0457]\u001b[A\n",
            "Epoch 1/5:  56% 103/185 [00:37<00:28,  2.88it/s, loss=0.3035]\u001b[A\n",
            "Epoch 1/5:  56% 104/185 [00:37<00:28,  2.84it/s, loss=0.3035]\u001b[A\n",
            "Epoch 1/5:  56% 104/185 [00:37<00:28,  2.84it/s, loss=0.4531]\u001b[A\n",
            "Epoch 1/5:  57% 105/185 [00:37<00:28,  2.82it/s, loss=0.4531]\u001b[A\n",
            "Epoch 1/5:  57% 105/185 [00:38<00:28,  2.82it/s, loss=0.4623]\u001b[A\n",
            "Epoch 1/5:  57% 106/185 [00:38<00:28,  2.80it/s, loss=0.4623]\u001b[A\n",
            "Epoch 1/5:  57% 106/185 [00:38<00:28,  2.80it/s, loss=0.8146]\u001b[A\n",
            "Epoch 1/5:  58% 107/185 [00:38<00:27,  2.80it/s, loss=0.8146]\u001b[A\n",
            "Epoch 1/5:  58% 107/185 [00:38<00:27,  2.80it/s, loss=0.1087]\u001b[A\n",
            "Epoch 1/5:  58% 108/185 [00:38<00:27,  2.78it/s, loss=0.1087]\u001b[A\n",
            "Epoch 1/5:  58% 108/185 [00:39<00:27,  2.78it/s, loss=0.3598]\u001b[A\n",
            "Epoch 1/5:  59% 109/185 [00:39<00:27,  2.76it/s, loss=0.3598]\u001b[A\n",
            "Epoch 1/5:  59% 109/185 [00:39<00:27,  2.76it/s, loss=0.7070]\u001b[A\n",
            "Epoch 1/5:  59% 110/185 [00:39<00:27,  2.75it/s, loss=0.7070]\u001b[A\n",
            "Epoch 1/5:  59% 110/185 [00:39<00:27,  2.75it/s, loss=0.1534]\u001b[A\n",
            "Epoch 1/5:  60% 111/185 [00:39<00:27,  2.69it/s, loss=0.1534]\u001b[A\n",
            "Epoch 1/5:  60% 111/185 [00:40<00:27,  2.69it/s, loss=0.0421]\u001b[A\n",
            "Epoch 1/5:  61% 112/185 [00:40<00:26,  2.72it/s, loss=0.0421]\u001b[A\n",
            "Epoch 1/5:  61% 112/185 [00:40<00:26,  2.72it/s, loss=0.5515]\u001b[A\n",
            "Epoch 1/5:  61% 113/185 [00:40<00:26,  2.73it/s, loss=0.5515]\u001b[A\n",
            "Epoch 1/5:  61% 113/185 [00:40<00:26,  2.73it/s, loss=0.1720]\u001b[A\n",
            "Epoch 1/5:  62% 114/185 [00:40<00:26,  2.71it/s, loss=0.1720]\u001b[A\n",
            "Epoch 1/5:  62% 114/185 [00:41<00:26,  2.71it/s, loss=0.3892]\u001b[A\n",
            "Epoch 1/5:  62% 115/185 [00:41<00:25,  2.72it/s, loss=0.3892]\u001b[A\n",
            "Epoch 1/5:  62% 115/185 [00:41<00:25,  2.72it/s, loss=0.1778]\u001b[A\n",
            "Epoch 1/5:  63% 116/185 [00:41<00:21,  3.21it/s, loss=0.1778]\u001b[A\n",
            "Epoch 1/5:  63% 116/185 [00:41<00:21,  3.21it/s, loss=0.0732]\u001b[A\n",
            "Epoch 1/5:  63% 117/185 [00:41<00:22,  3.08it/s, loss=0.0732]\u001b[A\n",
            "Epoch 1/5:  63% 117/185 [00:42<00:22,  3.08it/s, loss=0.4727]\u001b[A\n",
            "Epoch 1/5:  64% 118/185 [00:42<00:22,  2.99it/s, loss=0.4727]\u001b[A\n",
            "Epoch 1/5:  64% 118/185 [00:42<00:22,  2.99it/s, loss=0.0852]\u001b[A\n",
            "Epoch 1/5:  64% 119/185 [00:42<00:19,  3.43it/s, loss=0.0852]\u001b[A\n",
            "Epoch 1/5:  64% 119/185 [00:42<00:19,  3.43it/s, loss=0.3106]\u001b[A\n",
            "Epoch 1/5:  65% 120/185 [00:42<00:20,  3.14it/s, loss=0.3106]\u001b[A\n",
            "Epoch 1/5:  65% 120/185 [00:43<00:20,  3.14it/s, loss=0.1060]\u001b[A\n",
            "Epoch 1/5:  65% 121/185 [00:43<00:21,  2.95it/s, loss=0.1060]\u001b[A\n",
            "Epoch 1/5:  65% 121/185 [00:43<00:21,  2.95it/s, loss=0.2111]\u001b[A\n",
            "Epoch 1/5:  66% 122/185 [00:43<00:21,  2.88it/s, loss=0.2111]\u001b[A\n",
            "Epoch 1/5:  66% 122/185 [00:43<00:21,  2.88it/s, loss=0.0464]\u001b[A\n",
            "Epoch 1/5:  66% 123/185 [00:43<00:21,  2.84it/s, loss=0.0464]\u001b[A\n",
            "Epoch 1/5:  66% 123/185 [00:44<00:21,  2.84it/s, loss=0.0321]\u001b[A\n",
            "Epoch 1/5:  67% 124/185 [00:44<00:21,  2.79it/s, loss=0.0321]\u001b[A\n",
            "Epoch 1/5:  67% 124/185 [00:44<00:21,  2.79it/s, loss=0.0895]\u001b[A\n",
            "Epoch 1/5:  68% 125/185 [00:44<00:21,  2.76it/s, loss=0.0895]\u001b[A\n",
            "Epoch 1/5:  68% 125/185 [00:45<00:21,  2.76it/s, loss=0.0904]\u001b[A\n",
            "Epoch 1/5:  68% 126/185 [00:45<00:21,  2.74it/s, loss=0.0904]\u001b[A\n",
            "Epoch 1/5:  68% 126/185 [00:45<00:21,  2.74it/s, loss=0.0314]\u001b[A\n",
            "Epoch 1/5:  69% 127/185 [00:45<00:19,  3.00it/s, loss=0.0314]\u001b[A\n",
            "Epoch 1/5:  69% 127/185 [00:45<00:19,  3.00it/s, loss=0.2108]\u001b[A\n",
            "Epoch 1/5:  69% 128/185 [00:45<00:19,  2.86it/s, loss=0.2108]\u001b[A\n",
            "Epoch 1/5:  69% 128/185 [00:46<00:19,  2.86it/s, loss=0.1298]\u001b[A\n",
            "Epoch 1/5:  70% 129/185 [00:46<00:19,  2.83it/s, loss=0.1298]\u001b[A\n",
            "Epoch 1/5:  70% 129/185 [00:46<00:19,  2.83it/s, loss=0.0852]\u001b[A\n",
            "Epoch 1/5:  70% 130/185 [00:46<00:19,  2.81it/s, loss=0.0852]\u001b[A\n",
            "Epoch 1/5:  70% 130/185 [00:46<00:19,  2.81it/s, loss=0.3431]\u001b[A\n",
            "Epoch 1/5:  71% 131/185 [00:46<00:17,  3.13it/s, loss=0.3431]\u001b[A\n",
            "Epoch 1/5:  71% 131/185 [00:47<00:17,  3.13it/s, loss=0.0579]\u001b[A\n",
            "Epoch 1/5:  71% 132/185 [00:47<00:17,  2.98it/s, loss=0.0579]\u001b[A\n",
            "Epoch 1/5:  71% 132/185 [00:47<00:17,  2.98it/s, loss=0.0235]\u001b[A\n",
            "Epoch 1/5:  72% 133/185 [00:47<00:17,  2.90it/s, loss=0.0235]\u001b[A\n",
            "Epoch 1/5:  72% 133/185 [00:47<00:17,  2.90it/s, loss=0.0390]\u001b[A\n",
            "Epoch 1/5:  72% 134/185 [00:47<00:17,  2.83it/s, loss=0.0390]\u001b[A\n",
            "Epoch 1/5:  72% 134/185 [00:48<00:17,  2.83it/s, loss=0.0506]\u001b[A\n",
            "Epoch 1/5:  73% 135/185 [00:48<00:17,  2.80it/s, loss=0.0506]\u001b[A\n",
            "Epoch 1/5:  73% 135/185 [00:48<00:17,  2.80it/s, loss=0.0892]\u001b[A\n",
            "Epoch 1/5:  74% 136/185 [00:48<00:17,  2.79it/s, loss=0.0892]\u001b[A\n",
            "Epoch 1/5:  74% 136/185 [00:48<00:17,  2.79it/s, loss=0.3050]\u001b[A\n",
            "Epoch 1/5:  74% 137/185 [00:48<00:17,  2.75it/s, loss=0.3050]\u001b[A\n",
            "Epoch 1/5:  74% 137/185 [00:49<00:17,  2.75it/s, loss=0.0809]\u001b[A\n",
            "Epoch 1/5:  75% 138/185 [00:49<00:17,  2.68it/s, loss=0.0809]\u001b[A\n",
            "Epoch 1/5:  75% 138/185 [00:49<00:17,  2.68it/s, loss=0.0208]\u001b[A\n",
            "Epoch 1/5:  75% 139/185 [00:49<00:16,  2.71it/s, loss=0.0208]\u001b[A\n",
            "Epoch 1/5:  75% 139/185 [00:49<00:16,  2.71it/s, loss=0.0425]\u001b[A\n",
            "Epoch 1/5:  76% 140/185 [00:49<00:15,  2.87it/s, loss=0.0425]\u001b[A\n",
            "Epoch 1/5:  76% 140/185 [00:50<00:15,  2.87it/s, loss=0.1849]\u001b[A\n",
            "Epoch 1/5:  76% 141/185 [00:50<00:15,  2.82it/s, loss=0.1849]\u001b[A\n",
            "Epoch 1/5:  76% 141/185 [00:50<00:15,  2.82it/s, loss=0.0187]\u001b[A\n",
            "Epoch 1/5:  77% 142/185 [00:50<00:15,  2.80it/s, loss=0.0187]\u001b[A\n",
            "Epoch 1/5:  77% 142/185 [00:51<00:15,  2.80it/s, loss=0.0255]\u001b[A\n",
            "Epoch 1/5:  77% 143/185 [00:51<00:15,  2.78it/s, loss=0.0255]\u001b[A\n",
            "Epoch 1/5:  77% 143/185 [00:51<00:15,  2.78it/s, loss=0.0241]\u001b[A\n",
            "Epoch 1/5:  78% 144/185 [00:51<00:14,  2.76it/s, loss=0.0241]\u001b[A\n",
            "Epoch 1/5:  78% 144/185 [00:51<00:14,  2.76it/s, loss=0.0184]\u001b[A\n",
            "Epoch 1/5:  78% 145/185 [00:51<00:14,  2.74it/s, loss=0.0184]\u001b[A\n",
            "Epoch 1/5:  78% 145/185 [00:52<00:14,  2.74it/s, loss=0.0193]\u001b[A\n",
            "Epoch 1/5:  79% 146/185 [00:52<00:14,  2.67it/s, loss=0.0193]\u001b[A\n",
            "Epoch 1/5:  79% 146/185 [00:52<00:14,  2.67it/s, loss=0.2039]\u001b[A\n",
            "Epoch 1/5:  79% 147/185 [00:52<00:14,  2.68it/s, loss=0.2039]\u001b[A\n",
            "Epoch 1/5:  79% 147/185 [00:52<00:14,  2.68it/s, loss=0.0167]\u001b[A\n",
            "Epoch 1/5:  80% 148/185 [00:52<00:13,  2.70it/s, loss=0.0167]\u001b[A\n",
            "Epoch 1/5:  80% 148/185 [00:53<00:13,  2.70it/s, loss=0.2292]\u001b[A\n",
            "Epoch 1/5:  81% 149/185 [00:53<00:13,  2.68it/s, loss=0.2292]\u001b[A\n",
            "Epoch 1/5:  81% 149/185 [00:53<00:13,  2.68it/s, loss=0.0155]\u001b[A\n",
            "Epoch 1/5:  81% 150/185 [00:53<00:13,  2.67it/s, loss=0.0155]\u001b[A\n",
            "Epoch 1/5:  81% 150/185 [00:54<00:13,  2.67it/s, loss=0.0206]\u001b[A\n",
            "Epoch 1/5:  82% 151/185 [00:54<00:12,  2.63it/s, loss=0.0206]\u001b[A\n",
            "Epoch 1/5:  82% 151/185 [00:54<00:12,  2.63it/s, loss=0.0513]\u001b[A\n",
            "Epoch 1/5:  82% 152/185 [00:54<00:12,  2.67it/s, loss=0.0513]\u001b[A\n",
            "Epoch 1/5:  82% 152/185 [00:54<00:12,  2.67it/s, loss=0.0173]\u001b[A\n",
            "Epoch 1/5:  83% 153/185 [00:54<00:11,  2.69it/s, loss=0.0173]\u001b[A\n",
            "Epoch 1/5:  83% 153/185 [00:55<00:11,  2.69it/s, loss=0.0427]\u001b[A\n",
            "Epoch 1/5:  83% 154/185 [00:55<00:11,  2.71it/s, loss=0.0427]\u001b[A\n",
            "Epoch 1/5:  83% 154/185 [00:55<00:11,  2.71it/s, loss=0.3197]\u001b[A\n",
            "Epoch 1/5:  84% 155/185 [00:55<00:09,  3.26it/s, loss=0.3197]\u001b[A\n",
            "Epoch 1/5:  84% 155/185 [00:55<00:09,  3.26it/s, loss=0.5257]\u001b[A\n",
            "Epoch 1/5:  84% 156/185 [00:55<00:09,  3.10it/s, loss=0.5257]\u001b[A\n",
            "Epoch 1/5:  84% 156/185 [00:56<00:09,  3.10it/s, loss=0.0150]\u001b[A\n",
            "Epoch 1/5:  85% 157/185 [00:56<00:09,  2.98it/s, loss=0.0150]\u001b[A\n",
            "Epoch 1/5:  85% 157/185 [00:56<00:09,  2.98it/s, loss=0.1978]\u001b[A\n",
            "Epoch 1/5:  85% 158/185 [00:56<00:09,  2.89it/s, loss=0.1978]\u001b[A\n",
            "Epoch 1/5:  85% 158/185 [00:56<00:09,  2.89it/s, loss=0.0117]\u001b[A\n",
            "Epoch 1/5:  86% 159/185 [00:56<00:09,  2.81it/s, loss=0.0117]\u001b[A\n",
            "Epoch 1/5:  86% 159/185 [00:57<00:09,  2.81it/s, loss=0.0115]\u001b[A\n",
            "Epoch 1/5:  86% 160/185 [00:57<00:08,  2.78it/s, loss=0.0115]\u001b[A\n",
            "Epoch 1/5:  86% 160/185 [00:57<00:08,  2.78it/s, loss=0.0131]\u001b[A\n",
            "Epoch 1/5:  87% 161/185 [00:57<00:08,  2.76it/s, loss=0.0131]\u001b[A\n",
            "Epoch 1/5:  87% 161/185 [00:57<00:08,  2.76it/s, loss=0.0256]\u001b[A\n",
            "Epoch 1/5:  88% 162/185 [00:57<00:08,  2.72it/s, loss=0.0256]\u001b[A\n",
            "Epoch 1/5:  88% 162/185 [00:58<00:08,  2.72it/s, loss=0.0135]\u001b[A\n",
            "Epoch 1/5:  88% 163/185 [00:58<00:07,  3.09it/s, loss=0.0135]\u001b[A\n",
            "Epoch 1/5:  88% 163/185 [00:58<00:07,  3.09it/s, loss=0.0117]\u001b[A\n",
            "Epoch 1/5:  89% 164/185 [00:58<00:07,  2.98it/s, loss=0.0117]\u001b[A\n",
            "Epoch 1/5:  89% 164/185 [00:58<00:07,  2.98it/s, loss=0.0113]\u001b[A\n",
            "Epoch 1/5:  89% 165/185 [00:58<00:06,  2.95it/s, loss=0.0113]\u001b[A\n",
            "Epoch 1/5:  89% 165/185 [00:59<00:06,  2.95it/s, loss=0.0106]\u001b[A\n",
            "Epoch 1/5:  90% 166/185 [00:59<00:06,  2.88it/s, loss=0.0106]\u001b[A\n",
            "Epoch 1/5:  90% 166/185 [00:59<00:06,  2.88it/s, loss=0.5583]\u001b[A\n",
            "Epoch 1/5:  90% 167/185 [00:59<00:06,  2.81it/s, loss=0.5583]\u001b[A\n",
            "Epoch 1/5:  90% 167/185 [00:59<00:06,  2.81it/s, loss=0.0087]\u001b[A\n",
            "Epoch 1/5:  91% 168/185 [00:59<00:06,  2.76it/s, loss=0.0087]\u001b[A\n",
            "Epoch 1/5:  91% 168/185 [01:00<00:06,  2.76it/s, loss=0.0083]\u001b[A\n",
            "Epoch 1/5:  91% 169/185 [01:00<00:05,  2.73it/s, loss=0.0083]\u001b[A\n",
            "Epoch 1/5:  91% 169/185 [01:00<00:05,  2.73it/s, loss=0.0097]\u001b[A\n",
            "Epoch 1/5:  92% 170/185 [01:00<00:04,  3.20it/s, loss=0.0097]\u001b[A\n",
            "Epoch 1/5:  92% 170/185 [01:00<00:04,  3.20it/s, loss=0.0087]\u001b[A\n",
            "Epoch 1/5:  92% 171/185 [01:00<00:04,  3.01it/s, loss=0.0087]\u001b[A\n",
            "Epoch 1/5:  92% 171/185 [01:01<00:04,  3.01it/s, loss=0.0084]\u001b[A\n",
            "Epoch 1/5:  93% 172/185 [01:01<00:04,  2.91it/s, loss=0.0084]\u001b[A\n",
            "Epoch 1/5:  93% 172/185 [01:01<00:04,  2.91it/s, loss=0.4079]\u001b[A\n",
            "Epoch 1/5:  94% 173/185 [01:01<00:04,  2.82it/s, loss=0.4079]\u001b[A\n",
            "Epoch 1/5:  94% 173/185 [01:01<00:04,  2.82it/s, loss=0.0074]\u001b[A\n",
            "Epoch 1/5:  94% 174/185 [01:01<00:03,  2.79it/s, loss=0.0074]\u001b[A\n",
            "Epoch 1/5:  94% 174/185 [01:02<00:03,  2.79it/s, loss=0.0096]\u001b[A\n",
            "Epoch 1/5:  95% 175/185 [01:02<00:03,  2.76it/s, loss=0.0096]\u001b[A\n",
            "Epoch 1/5:  95% 175/185 [01:02<00:03,  2.76it/s, loss=0.4226]\u001b[A\n",
            "Epoch 1/5:  95% 176/185 [01:02<00:03,  2.73it/s, loss=0.4226]\u001b[A\n",
            "Epoch 1/5:  95% 176/185 [01:03<00:03,  2.73it/s, loss=0.0873]\u001b[A\n",
            "Epoch 1/5:  96% 177/185 [01:03<00:02,  2.70it/s, loss=0.0873]\u001b[A\n",
            "Epoch 1/5:  96% 177/185 [01:03<00:02,  2.70it/s, loss=0.0077]\u001b[A\n",
            "Epoch 1/5:  96% 178/185 [01:03<00:02,  3.21it/s, loss=0.0077]\u001b[A\n",
            "Epoch 1/5:  96% 178/185 [01:03<00:02,  3.21it/s, loss=0.8176]\u001b[A\n",
            "Epoch 1/5:  97% 179/185 [01:03<00:01,  3.04it/s, loss=0.8176]\u001b[A\n",
            "Epoch 1/5:  97% 179/185 [01:04<00:01,  3.04it/s, loss=0.0194]\u001b[A\n",
            "Epoch 1/5:  97% 180/185 [01:04<00:01,  2.94it/s, loss=0.0194]\u001b[A\n",
            "Epoch 1/5:  97% 180/185 [01:04<00:01,  2.94it/s, loss=0.0065]\u001b[A\n",
            "Epoch 1/5:  98% 181/185 [01:04<00:01,  2.86it/s, loss=0.0065]\u001b[A\n",
            "Epoch 1/5:  98% 181/185 [01:04<00:01,  2.86it/s, loss=0.0068]\u001b[A\n",
            "Epoch 1/5:  98% 182/185 [01:04<00:00,  3.08it/s, loss=0.0068]\u001b[A\n",
            "Epoch 1/5:  98% 182/185 [01:05<00:00,  3.08it/s, loss=0.6312]\u001b[A\n",
            "Epoch 1/5:  99% 183/185 [01:05<00:00,  2.95it/s, loss=0.6312]\u001b[A\n",
            "Epoch 1/5:  99% 183/185 [01:05<00:00,  2.95it/s, loss=0.0127]\u001b[A\n",
            "Epoch 1/5:  99% 184/185 [01:05<00:00,  3.51it/s, loss=0.0127]\u001b[A\n",
            "Epoch 1/5:  99% 184/185 [01:05<00:00,  3.51it/s, loss=0.0074]\u001b[A\n",
            "Epoch 1/5: 100% 185/185 [01:05<00:00,  3.57it/s, loss=0.0074]\u001b[A\n",
            "  Epoch 1/5 | loss=0.3447 | val_acc=97.25% | val_F1=0.9723 << BEST\n",
            "  Epoch 2/5 | loss=0.1160 | val_acc=96.15% | val_F1=0.9611\n",
            "  Epoch 3/5 | loss=0.0395 | val_acc=97.25% | val_F1=0.9723\n",
            "  Epoch 4/5 | loss=0.0291 | val_acc=97.80% | val_F1=0.9779 << BEST\n",
            "  Epoch 5/5 | loss=0.0184 | val_acc=97.80% | val_F1=0.9779\n",
            "\n",
            "================================================================================\n",
            "EVALUATION (best epoch = 4)\n",
            "================================================================================\n",
            "  Optimal threshold (val): 0.30 (F1=0.9779)\n",
            "                                          \n",
            "  TEST RESULTS:\n",
            "  Accuracy:     96.20%\n",
            "  Macro F1:     0.9615\n",
            "  F1 (FAKE):    0.9571\n",
            "  F1 (REAL):    0.9659\n",
            "  Gap:          0.0088\n",
            "  Threshold:    0.30\n",
            "\n",
            "  Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    REAL (0)     0.9340    1.0000    0.9659        99\n",
            "    FAKE (1)     1.0000    0.9176    0.9571        85\n",
            "\n",
            "    accuracy                         0.9620       184\n",
            "   macro avg     0.9670    0.9588    0.9615       184\n",
            "weighted avg     0.9645    0.9620    0.9618       184\n",
            "\n",
            "\n",
            "  Model saved: /content/outputs/phobert_model/best_model_state_dict.pt\n",
            "  Tokenizer saved: /content/outputs/phobert_model/tokenizer\n",
            "  Results saved: /content/outputs/phobert_model/results.json\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETE [OK]\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "MODEL_NAME = \"vinai/phobert-base\"\n",
        "CKPT_PATH  = \"/content/outputs/phobert_model/best_model_state_dict.pt\"\n",
        "\n",
        "id2label = {0: \"REAL\", 1: \"FAKE\"}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
        "\n",
        "state_dict = torch.load(CKPT_PATH, map_location=device)\n",
        "missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
        "print(\"Missing keys:\", missing[:10], \"...\" if len(missing) > 10 else \"\")\n",
        "print(\"Unexpected keys:\", unexpected[:10], \"...\" if len(unexpected) > 10 else \"\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_text(text: str, max_length: int = 256):\n",
        "    enc = tokenizer(text, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "    logits = model(**enc).logits\n",
        "    probs = torch.softmax(logits, dim=-1).squeeze(0)\n",
        "    pred_id = int(torch.argmax(probs).item())\n",
        "\n",
        "    return {\n",
        "        \"label\": id2label[pred_id],\n",
        "        \"prob_real\": float(probs[0].item()),\n",
        "        \"prob_fake\": float(probs[1].item()),\n",
        "    }\n",
        "\n",
        "while True:\n",
        "    text = input(\"\\nNhập tin (q để thoát): \").strip()\n",
        "    if text.lower() in [\"q\", \"quit\", \"exit\"]:\n",
        "        break\n",
        "    if not text:\n",
        "        print(\"Bạn chưa nhập gì.\")\n",
        "        continue\n",
        "    out = predict_text(text)\n",
        "    print(f\"→ {out['label']} | P(REAL)={out['prob_real']:.4f} | P(FAKE)={out['prob_fake']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9024b4bd227642559c089b6ba0227743",
            "694ef61586c1497889ff762f59897776",
            "591411da12ea4e8db58d06c07b0820fa",
            "f983f68c156d4debb3536c4da4d0181c",
            "ba07908e4fca4e8a8a53f52a33536e74",
            "778a7adc3f2a44558c1c343170d7a1d9",
            "ca9b909b4aab498c808765a7b08cb3d4",
            "9b461ebc5c314805ab20989b8047bc5a",
            "095670fc94bc40d5a592aad1fa32143f",
            "41b5dae7efc34acd8c9c251838973107",
            "13c9f2441850422fbc5da6b3cc253f0c"
          ]
        },
        "id": "sGOuBMm3hAEt",
        "outputId": "d450f637-1689-4007-f1a5-656e87c57c70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9024b4bd227642559c089b6ba0227743"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RobertaForSequenceClassification LOAD REPORT from: vinai/phobert-base\n",
            "Key                             | Status     | \n",
            "--------------------------------+------------+-\n",
            "roberta.pooler.dense.bias       | UNEXPECTED | \n",
            "lm_head.layer_norm.bias         | UNEXPECTED | \n",
            "lm_head.layer_norm.weight       | UNEXPECTED | \n",
            "roberta.pooler.dense.weight     | UNEXPECTED | \n",
            "lm_head.dense.weight            | UNEXPECTED | \n",
            "lm_head.decoder.weight          | UNEXPECTED | \n",
            "roberta.embeddings.position_ids | UNEXPECTED | \n",
            "lm_head.dense.bias              | UNEXPECTED | \n",
            "lm_head.decoder.bias            | UNEXPECTED | \n",
            "lm_head.bias                    | UNEXPECTED | \n",
            "classifier.out_proj.weight      | MISSING    | \n",
            "classifier.dense.weight         | MISSING    | \n",
            "classifier.dense.bias           | MISSING    | \n",
            "classifier.out_proj.bias        | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing keys: [] \n",
            "Unexpected keys: [] \n",
            "\n",
            "Nhập tin (q để thoát): Chủ tịch nước Cộng hòa xã hội chủ nghĩa Việt Nam hiện tại (nhiệm kỳ 2021-2026) là Đại tướng Lương Cường\n",
            "→ FAKE | P(REAL)=0.0005 | P(FAKE)=0.9995\n",
            "\n",
            "Nhập tin (q để thoát): Chủ tịch nước Cộng hòa xã hội chủ nghĩa Việt Nam hiện tại (nhiệm kỳ 2021-2026) là Tô Lâm\n",
            "→ FAKE | P(REAL)=0.0005 | P(FAKE)=0.9995\n",
            "\n",
            "Nhập tin (q để thoát): Theo báo Tuổi Trẻ ngày 12/1, Bộ Giáo dục cho biết kỳ thi tốt nghiệp THPT năm nay vẫn giữ nguyên hình thức như năm trước.\n",
            "→ FAKE | P(REAL)=0.3024 | P(FAKE)=0.6976\n",
            "\n",
            "Nhập tin (q để thoát): Messi có 6 quả bóng vàng\n",
            "→ FAKE | P(REAL)=0.0006 | P(FAKE)=0.9994\n",
            "\n",
            "Nhập tin (q để thoát): Messi có 5 quả bóng vàng\n",
            "→ FAKE | P(REAL)=0.0006 | P(FAKE)=0.9994\n",
            "\n",
            "Nhập tin (q để thoát): Messi có 4 quả bóng vàng\n",
            "→ FAKE | P(REAL)=0.0006 | P(FAKE)=0.9994\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4063639218.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nNhập tin (q để thoát): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}